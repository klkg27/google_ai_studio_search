{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee1a7a6b-3c4f-49d7-9e9f-bfdb623f0309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f16bed2-7f52-436f-8521-33a72fb3da07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d6d28-4249-4b20-80d1-c6f051dd6a44",
   "metadata": {},
   "source": [
    "# DeepSeek 名单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b1054c18-1509-4b21-a21e-67b437c98757",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_names = [\n",
    "    \"Aixin Liu\", \"Bing Xue\", \"Bingxuan Wang\", \"Bochao Wu\", \"Chengda Lu\", \n",
    "    \"Chenggang Zhao\", \"Chengqi Deng\", \"Chenyu Zhang*\", \"Chong Ruan\", \"Damai Dai\", \n",
    "    \"Daya Guo\", \"Dejian Yang\", \"Deli Chen\", \"Erhang Li\", \"Fangyun Lin\", \n",
    "    \"Fucong Dai\", \"Fuli Luo*\", \"Guangbo Hao\", \"Guanting Chen\", \"Guowei Li\", \n",
    "     \"H. Zhang\", \"Han Bao*\", \"Hanwei Xu\", \"Haocheng Wang*\", \"Haowei Zhang\", \n",
    "     \"Honghui Ding\", \"Huajian Xin*\", \"Huazuo Gao\", \"Hui Qu\", \"Jianzhong Guo\", \n",
    "     \"Jiashi Li\", \"Jiawei Wang*\", \"Jingchang Chen\", \"Jingyang Yuan\", \"Junjie Qiu\", \n",
    "     \"Junlong Li\", \"Junxiao Song\", \"Kai Dong\", \"Kai Hu*\", \"Kaige Gao\", \"Kang Guan\", \n",
    "     \"Kexin Huang\", \"Kuai Yu\", \"Lean Wang\", \"Lecong Zhang\", \"Liang Zhao\", \n",
    "     \"Litong Wang\", \"Liyue Zhang\", \"Mingchuan Zhang\", \"Minghua Zhang\", \"Minghui Tang\", \n",
    "     \"Panpan Huang\", \"Peiyi Wang\", \"Qiancheng Wang\", \"Qihao Zhu\", \"Qinyu Chen\", \n",
    "     \"Qiushi Du\", \"Ruiqi Ge\", \"Ruisong Zhang\", \"Ruizhe Pan\", \"Runji Wang\", \n",
    "     \"Runxin Xu\", \"Ruoyu Zhang\", \"Shanghao Lu\", \"Shangyan Zhou\", \"Shanhuang Chen\", \n",
    "     \"Shengfeng Ye\", \"Shirong Ma\", \"Shiyu Wang\", \"Shuiping Yu\", \"Shunfeng Zhou\", \n",
    "    \"Shuting Pan\", \"Tao Yun\", \"Tian Pei\", \"Wangding Zeng\", \"Wanjia Zhao*\",\n",
    "    \"Wen Liu\", \"Wenfeng Liang\", \"Wenjun Gao\", \"Wenqin Yu\", \"Wentao Zhang\",\n",
    "     \"Xiao Bi\", \"Xiaodong Liu\", \"Xiaohan Wang\", \"Xiaokang Chen\", \"Xiaokang Zhang\",\n",
    "     \"Xiaotao Nie\", \"Xin Cheng\", \"Xin Liu\", \"Xin Xie\", \"Xingchao Liu\", \"Xingkai Yu\",\n",
    "    \"Xinyu Yang\", \"Xinyuan Li\", \"Xuecheng Su\", \"Xuheng Lin\", \"Y.K. Li\", \"Y.Q. Wang\", \n",
    "    \"Y.X. Wei\", \"Yang Zhang\", \"Yanhong Xu\", \"Yao Li\", \"Yao Zhao\", \"Yaofeng Sun\",\n",
    "     \"Yaohui Wang\", \"Yi Yu\", \"Yichao Zhang\", \"Yifan Shi\", \"Yiliang Xiong\", \"Ying He\",\n",
    "     \"Yishi Piao\", \"Yisong Wang\", \"Yixuan Tan\", \"Yiyang Ma*\", \"Yiyuan Liu\",\n",
    "     \"Yongqiang Guo\", \"Yu Wu\", \"Yuan Ou\", \"Yuduan Wang\", \"Yue Gong\", \"Yuheng Zou\",\n",
    "     \"Yujia He\", \"Yunfan Xiong\", \"Yuxiang Luo\", \"Yuxiang You\", \"Yuxuan Liu\",\n",
    "     \"Yuyang Zhou\", \"Z.F. Wu\", \"Z.Z. Ren\", \"Zehui Ren\", \"Zhangli Sha\", \"Zhe Fu\",\n",
    "    \"Zhean Xu\", \"Zhenda Xie\", \"Zhengyan Zhang\", \"Zhewen Hao\", \"Zhibin Gou\", \"Zhicheng Ma\", \n",
    "    \"Zhigang Yan\", \"Zhihong Shao\", \"Zhiyu Wu\", \"Zhuoshu Li\", \"Zihui Gu\", \"Zijia Zhu\",\n",
    "    \"Zijun Liu*\", \"Zilin Li\", \"Ziwei Xie\", \"Ziyang Song\", \"Ziyi Gao\", \"Zizheng Pan\",\n",
    "    \"Bei Feng\", \"Hui Li\", \"J.L. Cai\", \"Jiaqi Ni\", \"Lei Xu\", \"Meng Li\", \"Ning Tian\",\n",
    "     \"R.J. Chen\", \"R.L. Jin\", \"Ruyi Chen\", \"S.S. Li\", \"Shuang Zhou\", \"Tianyu Sun\",\n",
    "     \"X.Q. Li\", \"Xiangyue Jin\", \"Xiaojin Shen\", \"Xiaosha Chen\", \"Xiaowen Sun\",\n",
    "     \"Xiaoxiang Wang\", \"Xinnan Song\", \"Xinyi Zhou\", \"Y.X. Zhu\", \"Yanhong Xu\",\n",
    "     \"Yanping Huang\", \"Yaohui Li\", \"Yi Zheng\", \"Yuchen Zhu\", \"Yunxian Ma\",\n",
    "      \"Zhen Huang\", \"Zhipeng Xu\", \"Zhongyu Zhang\", \"Dongjie Ji\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717e885-35e1-4563-a99b-95254da2c6ed",
   "metadata": {},
   "source": [
    "# google search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4ec70c1d-2ee1-451c-8bc8-b411d024ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import Tool, GenerateContentConfig, GoogleSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bca8fd66-d961-468a-a42b-1cea04315fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_google = genai.Client(api_key=\"AIzaSyApvkwJGjToevvVdvyvY4ScIIlohqVs_Zc\")\n",
    "model_id = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "google_search_tool = Tool(\n",
    "    google_search = GoogleSearch()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd7e014d-b5d5-4440-97f2-273a0ff8ff76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a professional profile of Damai Dai, based on the information I've gathered:\n",
      "\n",
      "**### Basic Information**\n",
      "\n",
      "*   **Name:** Damai Dai\n",
      "*   **Current Affiliation:** DeepSeek AI (DL Researcher)\n",
      "*   **Previous Affiliation:** Peking University\n",
      "*   **Google Scholar Profile Link:** [https://scholar.google.com/citations?user=h8sXy88AAAAJ](https://scholar.google.com/citations?user=h8sXy88AAAAJ)\n",
      "\n",
      "**### Article List**\n",
      "\n",
      "Here are some of Damai Dai's main articles, along with their citation counts (note that citation counts can vary slightly between sources and are approximate as of today's date):\n",
      "\n",
      "1.  **Knowledge Neurons in Pretrained Transformers** (2021) - 356 citations\n",
      "2.  **A Survey on In-context Learning** (2022) - 311 citations\n",
      "3.  **Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers** (2023) - 235 citations\n",
      "4.  **Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts** (2024) - Citations not available\n",
      "5.  **DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence** (2024) - Citations not available\n",
      "6.  **Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning** (2023) - Citations not available\n",
      "7.  **Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations** (2023) - Citations not available\n",
      "8.  **Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models** (2024) - Citations not available\n",
      "9. **DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model** (2024) - Citations not available\n",
      "10. **On the Representation Collapse of Sparse Mixture of Experts** (2022) - Citations not available\n",
      "\n",
      "**### Other Related Articles**\n",
      "\n",
      "Damai Dai has also published several other articles in fields such as:\n",
      "\n",
      "*   **Deep Learning**\n",
      "*   **Natural Language Processing**\n",
      "*   **Large Language Models**\n",
      "*  **Mixture-of-Experts**\n",
      "*   **Semantic Parsing**\n",
      "*   **Language Modeling**\n",
      "*   **Knowledge**\n",
      "*   **Attribution**\n",
      "*    **Mathematical Reasoning**\n",
      "*   **Knowledge Graph Completion**\n",
      "*  **Optimal Estimation**\n",
      "*  **Translational Assumption**\n",
      "\n",
      "For more details and a complete list of publications, please visit their Google Scholar profile.\n",
      "\n",
      "**Summary of Damai Dai's Profile**\n",
      "\n",
      "Damai Dai is a researcher at DeepSeek AI with a strong background in Natural Language Processing and Deep Learning, particularly in Large Language Models. Their work focuses on understanding and improving the capabilities of these models, including areas such as in-context learning, mixture-of-experts, and knowledge representation within the models. They have published many papers in top-tier conferences and journals and have a strong citation record. Their research also extends to the application of Large language models in code and math.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "response_info = client_google.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=f\"What is the professional profile of Damai Dai at DeepSeek AI. Give response in markdown\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[google_search_tool],\n",
    "        response_modalities=[\"TEXT\"],\n",
    "    )\n",
    ")\n",
    "collected_text_list = []\n",
    "for each in response_info.candidates[0].content.parts:\n",
    "    collected_text_list.append(each.text)\n",
    "info_text = \"\\n\".join(collected_text_list)\n",
    "print(info_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9fe52e7c-f7d6-4289-ad41-a76ed193f84e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/182 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m tqdm(deepseek_names):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m         response_info \u001b[38;5;241m=\u001b[39m client_google\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m      7\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m      8\u001b[0m             contents\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the professional profile of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at DeepSeek AI. Give response in markdown.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m             config\u001b[38;5;241m=\u001b[39mGenerateContentConfig(\n\u001b[1;32m     10\u001b[0m                 tools\u001b[38;5;241m=\u001b[39m[google_search_tool],\n\u001b[1;32m     11\u001b[0m                 response_modalities\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEXT\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     12\u001b[0m             )\n\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m         collected_text_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m response_info\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mparts:\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/google/genai/models.py:4405\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4403\u001b[0m automatic_function_calling_history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   4404\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 4405\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[1;32m   4406\u001b[0m       model\u001b[38;5;241m=\u001b[39mmodel, contents\u001b[38;5;241m=\u001b[39mcontents, config\u001b[38;5;241m=\u001b[39mconfig\n\u001b[1;32m   4407\u001b[0m   )\n\u001b[1;32m   4408\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4409\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/google/genai/models.py:3667\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   3664\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   3665\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mapply_base64_encoding(request_dict)\n\u001b[0;32m-> 3667\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m   3668\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, path, request_dict, http_options\n\u001b[1;32m   3669\u001b[0m )\n\u001b[1;32m   3671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[1;32m   3672\u001b[0m   response_dict \u001b[38;5;241m=\u001b[39m _GenerateContentResponse_from_vertex(\n\u001b[1;32m   3673\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client, response_dict\n\u001b[1;32m   3674\u001b[0m   )\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/google/genai/_api_client.py:325\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m     http_options: HttpOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    321\u001b[0m ):\n\u001b[1;32m    322\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m    323\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m    324\u001b[0m   )\n\u001b[0;32m--> 325\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(http_request, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    326\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m http_options \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_payload\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m http_options:\n\u001b[1;32m    327\u001b[0m     response\u001b[38;5;241m.\u001b[39mcopy_to_dict(http_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_payload\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/google/genai/_api_client.py:263\u001b[0m, in \u001b[0;36mApiClient._request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    260\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    261\u001b[0m   )\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_unauthorized(http_request, stream)\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/google/genai/_api_client.py:284\u001b[0m, in \u001b[0;36mApiClient._request_unauthorized\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    277\u001b[0m http_session \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m    278\u001b[0m request \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    279\u001b[0m     method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    280\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m    281\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    282\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    283\u001b[0m )\u001b[38;5;241m.\u001b[39mprepare()\n\u001b[0;32m--> 284\u001b[0m response \u001b[38;5;241m=\u001b[39m http_session\u001b[38;5;241m.\u001b[39msend(request, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    285\u001b[0m errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    287\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    288\u001b[0m )\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/old/Env1/mistral/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop\n",
    "all_results = dict()\n",
    "error_dict = dict()\n",
    "for name in tqdm(deepseek_names):\n",
    "    try:\n",
    "        response_info = client_google.models.generate_content(\n",
    "            model=model_id,\n",
    "            contents=f\"What is the professional profile of {name} at DeepSeek AI. Give response in markdown.\",\n",
    "            config=GenerateContentConfig(\n",
    "                tools=[google_search_tool],\n",
    "                response_modalities=[\"TEXT\"],\n",
    "            )\n",
    "        )\n",
    "        collected_text_list = []\n",
    "        for each in response_info.candidates[0].content.parts:\n",
    "            collected_text_list.append(each.text)\n",
    "        info_text = \"\\n\".join(collected_text_list)\n",
    "        all_results[name] = info_text\n",
    "        time.sleep(3) #每分钟最多10次request，限制访问频率\n",
    "    except Exception as e:\n",
    "        error_dict[name] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "35be1963-2f4e-41b7-aad0-21eba104f843",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "af939e7f-e697-4f3c-a362-7d1ff0d914b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Xiaokang Chen': requests.exceptions.SSLError(urllib3.exceptions.MaxRetryError(\"HTTPSConnectionPool(host='generativelanguage.googleapis.com', port=443): Max retries exceeded with url: /v1beta/models/gemini-2.0-flash-exp:generateContent (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)')))\")),\n",
       " 'Xiaokang Zhang': requests.exceptions.SSLError(urllib3.exceptions.MaxRetryError(\"HTTPSConnectionPool(host='generativelanguage.googleapis.com', port=443): Max retries exceeded with url: /v1beta/models/gemini-2.0-flash-exp:generateContent (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)')))\")),\n",
       " 'Xiaotao Nie': requests.exceptions.SSLError(urllib3.exceptions.MaxRetryError(\"HTTPSConnectionPool(host='generativelanguage.googleapis.com', port=443): Max retries exceeded with url: /v1beta/models/gemini-2.0-flash-exp:generateContent (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)')))\")),\n",
       " 'Xin Cheng': requests.exceptions.SSLError(urllib3.exceptions.MaxRetryError(\"HTTPSConnectionPool(host='generativelanguage.googleapis.com', port=443): Max retries exceeded with url: /v1beta/models/gemini-2.0-flash-exp:generateContent (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)')))\")),\n",
       " 'Xuheng Lin': requests.exceptions.SSLError(urllib3.exceptions.MaxRetryError(\"HTTPSConnectionPool(host='generativelanguage.googleapis.com', port=443): Max retries exceeded with url: /v1beta/models/gemini-2.0-flash-exp:generateContent (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)')))\")),\n",
       " 'Yiyuan Liu': requests.exceptions.SSLError(urllib3.exceptions.MaxRetryError(\"HTTPSConnectionPool(host='generativelanguage.googleapis.com', port=443): Max retries exceeded with url: /v1beta/models/gemini-2.0-flash-exp:generateContent (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)')))\")),\n",
       " 'Yuduan Wang': requests.exceptions.SSLError(urllib3.exceptions.MaxRetryError(\"HTTPSConnectionPool(host='generativelanguage.googleapis.com', port=443): Max retries exceeded with url: /v1beta/models/gemini-2.0-flash-exp:generateContent (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)')))\")),\n",
       " 'Ziyi Gao': requests.exceptions.ConnectionError(urllib3.exceptions.ProtocolError('Connection aborted.',\n",
       "                                                                      ConnectionResetError(104,\n",
       "                                                                                           'Connection reset by peer'))),\n",
       " 'R.L. Jin': google.genai.errors.ClientError(\"400 FAILED_PRECONDITION. {'error': {'code': 400, 'message': 'User location is not supported for the API use.', 'status': 'FAILED_PRECONDITION'}}\")}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a59d32c-f59b-49bf-80d4-cd1f6036b33b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_info = all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0618a1c5-8502-45cd-99ec-9d132f10d5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aixin Liu is a key researcher at DeepSeek AI, contributing significantly to the development of their large language models. Here's a breakdown of their professional profile based on the provided search results:\n",
      "\n",
      "**Key Contributions:**\n",
      "\n",
      "*   **Lead Author/Contributor:** Aixin Liu is consistently listed as a lead author or major contributor in numerous research papers from DeepSeek AI. These papers detail the development and advancements of their large language models, including:\n",
      "    *   **DeepSeek-V2:** A strong and efficient Mixture-of-Experts (MoE) language model.\n",
      "    *   **DeepSeek-V3:** A more advanced MoE model with 671 billion parameters, known for its efficiency and performance.\n",
      "    *    **DeepSeek-Coder-V2:** An open-source MoE code model with capabilities comparable to GPT-4 Turbo.\n",
      "   * **DeepSeek-VL2**: A vision-language model.\n",
      "*   **Model Architecture and Training:** Aixin Liu is involved in the research and implementation of key architectural components in DeepSeek's models, such as:\n",
      "    *   **Multi-head Latent Attention (MLA):** A technique used in DeepSeek-V3 to optimize attention mechanisms and enhance efficiency.\n",
      "    *   **DeepSeekMoE Framework:** An auxiliary-loss-free strategy for effective load balancing among specialized experts within MoE models.\n",
      "    *   **Multi-token Prediction Training Objective:** A method to improve context understanding by simultaneously predicting multiple future tokens.\n",
      "\n",
      "**Areas of Expertise:**\n",
      "\n",
      "*   **Large Language Models (LLMs):** Aixin Liu's work primarily revolves around the development of large language models, showcasing expertise in areas such as model architecture, training methodologies, and performance optimization.\n",
      "*   **Mixture-of-Experts (MoE):** They are deeply involved in developing and refining MoE models, a type of neural network architecture that improves efficiency and performance.\n",
      "*   **Code Intelligence:** Their contributions to DeepSeek-Coder-V2 highlight expertise in applying LLMs to code-related tasks.\n",
      "*   **Multimodal Learning:** Aixin Liu is also involved with development of Vision-Language models such as DeepSeek-VL2, indicating expertise in multimodal learning.\n",
      "\n",
      "**Other Notable Points:**\n",
      "\n",
      "*   **Collaboration:** Aixin Liu frequently collaborates with other researchers at DeepSeek AI, as evidenced by the extensive author lists on their published papers.\n",
      "*   **Open Source:** Aixin Liu has contributed to the development of open-source models such as DeepSeek-Coder-V2, indicating a commitment to making AI advancements accessible to the wider community.\n",
      "\n",
      "In summary, Aixin Liu is a key researcher at DeepSeek AI, with a strong focus on large language models, Mixture-of-Experts architectures, and various aspects of model training and optimization. Their work is instrumental in the development of efficient and high-performing models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result_info['Aixin Liu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ae9f70f-eeb9-4810-aa7e-c10d9190a504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Damai Dai is a Deep Learning Researcher at DeepSeek AI. His research interests include:\n",
      "\n",
      "*   **Abstract Meaning Representation**\n",
      "*   **Transformer Networks**\n",
      "*   **Curriculum Learning**\n",
      "*   **Semantic Parsing**\n",
      "*  **Language Modeling**\n",
      "*   **Knowledge Representation**\n",
      "*   **Large Language Models**\n",
      "*   **Neural Machine Translation (NMT)**\n",
      "*   **Attribution**\n",
      "*   **Mathematical Reasoning**\n",
      "*   **Knowledge Graph Completion**\n",
      "*   **Mixture-of-Experts Models**\n",
      "*   **Optimal Estimation**\n",
      "*   **Translational Assumption**\n",
      "*   **In-Context Learning**\n",
      "\n",
      "He has also worked on:\n",
      "\n",
      "*   **Chinese Word Sense Disambiguation**\n",
      "*   **Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts**\n",
      "*   **Code Intelligence**\n",
      "*   **Factual Knowledge Calibration in Pretrained Language Models**\n",
      "\n",
      "Damai Dai has contributed to several research papers, including:\n",
      "\n",
      "*   **Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations**\n",
      "*   **Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning**\n",
      "*   **Knowledge Neurons in Pretrained Transformers**\n",
      "*   **StableMoE: Stable Routing Strategy for Mixture of Experts**\n",
      "*   **DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model**\n",
      "*   **DeepSeek LLM Scaling Open-Source Language Models with Longtermism**\n",
      "*    **DeepSeek-V3 Technical Report**\n",
      "\n",
      "He is also associated with the following:\n",
      "*   Peking University (where he is a Ph.D. student)\n",
      "*  Google Scholar (with 3528 citations)\n",
      "*  Semantic Scholar (with 233 highly influential citations and 39 research papers)\n",
      "\n",
      "He is an active contributor to the AI community, with a profile on Hugging Face as DeepSeekDDM.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result_info['Damai Dai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2f0cc-f93f-4986-b8cb-5a3cc80e315c",
   "metadata": {},
   "source": [
    "# perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31385616-8ffc-48bb-8cab-85e8bf6d5e1a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"bc68588e-40bc-42d1-b251-ad7da566683b\", \"model\": \"llama-3.1-sonar-small-128k-online\", \"created\": 1735800157, \"usage\": {\"prompt_tokens\": 18, \"completion_tokens\": 294, \"total_tokens\": 312}, \"citations\": [\"https://xiaomitime.com/xiaomis-big-step-to-ai-luo-fuli-joined-xiaomi-ai-lab-to-develop-large-models-lead-19938/\", \"https://www.aibase.com/news/14176\", \"https://www.aibase.com/news/14345\", \"http://www.aastocks.com/en/stocks/news/aafn-con/NOW.1407307/popular-news/AAFN\", \"https://www.digitimes.com/news/a20241231PD211/xiaomi-ai-talent-automotive-development.html\"], \"object\": \"chat.completion\", \"choices\": [{\"index\": 0, \"finish_reason\": \"stop\", \"message\": {\"role\": \"assistant\", \"content\": \"Fuli Luo is a prominent AI researcher known for her work on large-scale AI models. Here are some key points about her:\\n\\n- **Background**: Fuli Luo holds a master's degree from the Institute of Computational Linguistics at Peking University and has published several papers at top conferences in natural language processing, such as ACL2019[2][3].\\n- **Career**: She began her career at Alibaba's DAMO Academy, where she developed the multilingual pre-training model VECO and promoted the open-source work of AliceMind[1][2].\\n- **DeepSeek**: In 2022, Luo joined DeepSeek and contributed to the development of the DeepSeek-V2, an advanced large model MoE[1][2][3].\\n- **Xiaomi Recruitment**: Recently, she was recruited by Xiaomi to lead its large model team at the Xiaomi AI Lab, with a multi-million yuan salary offer from Lei Jun, the founder of Xiaomi[1][2][3].\\n\\nHowever, as of the latest reports, there is some uncertainty regarding her decision to join Xiaomi, with her high school homeroom teacher stating that she is still under consideration[4].\\n\\nFor more detailed information about Fuli Luo's academic and professional profile, you can refer to her publications and research contributions. Unfortunately, there is no direct link to her Google Scholar profile provided in the sources. You would need to search for her name on Google Scholar to find her profile.\"}, \"delta\": {\"role\": \"assistant\", \"content\": \"\"}}]}\n"
     ]
    }
   ],
   "source": [
    "###可调参数，暂未使用这种方式\n",
    "import requests\n",
    "\n",
    "url = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"llama-3.1-sonar-small-128k-online\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"return the Google Scholar profile url for the person associated with DeepSeek AI.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Fuli Luo\"\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": \"4096\",\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 0.9,\n",
    "    \"search_domain_filter\": [\"perplexity.ai\"],\n",
    "    \"return_images\": False,\n",
    "    \"return_related_questions\": False,\n",
    "    \"search_recency_filter\": \"month\",\n",
    "    \"top_k\": 0,\n",
    "    \"stream\": False,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"frequency_penalty\": 1\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer 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\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "129bdc72-4857-47ab-aaf2-97c55608d477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 基本信息\n",
      "- **姓名**: Fuli Luo（罗福莉）\n",
      "- **Google Scholar 个人主页链接**: [Fuli Luo - Google Scholar](https://scholar.google.com/citations?user=1s79Z5cAAAAJ&hl=zh-CN)\n",
      "\n",
      "### 文章列表\n",
      "以下是 Fuli Luo 的主要文章及其引用情况:\n",
      "\n",
      "1. **DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence** (2024) - 392 引用。\n",
      "2. **A dual reinforcement learning framework for unsupervised text style transfer** (2019) - 191 引用。\n",
      "3. **Enhancing topic-to-essay generation with external commonsense knowledge** (2019) - 97 引用。\n",
      "4. **A deep reinforced sequence-to-set model for multi-label classification** (2019) - 78 引用。\n",
      "5. **Leveraging gloss knowledge in neural word sense disambiguation by hierarchical co-attention** (2018) - 78 引用。\n",
      "6. **Knowledgeable Storyteller: A Commonsense-Driven Generative Model for Visual Storytelling** (2019) - 74 引用。\n",
      "7. **DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence** (2024) - 71 引用。\n",
      "8. **VECO: Variable and flexible cross-lingual pre-training for language understanding and generation** (2020) - 67 引用。\n",
      "9. **A hierarchical reinforced sequence operation method for unsupervised text style transfer** (2019) - 66 引用。\n",
      "10. **Learning to control the fine-grained sentiment for story ending generation** (2019) - 64 引用。\n",
      "\n",
      "### 引用情况\n",
      "- **总引用次数**:\n",
      "  - 总计: 根据页面显示，Fuli Luo 的文章总引用次数超过 2000 次，但exact 数字未提供。\n",
      "  - 2020 年至今: 大部分高引用文章都在2020年之后发表。\n",
      "- **h 指数**:\n",
      "  - 总计: 未提供 exact h指数，但根据引用次数可以推断较高。\n",
      "  - 2019 年至今: 同样未提供 exact h指数，但近年来的高引用文章表明其影响力在持续增长。\n",
      "- **i10 指数**:\n",
      "  - 总计: 未提供。\n",
      "  - 2020 年至今: 未提供。\n",
      "\n",
      "### 其他相关文章\n",
      "Fuli Luo 还发表了多篇其他文章，涉及自然语言处理（NLP）、代码智能、文本风格转换、多标签分类、跨语言预训练等领域。更多详细信息请访问其 Google Scholar 个人主页。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "YOUR_API_KEY = \"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\"\n",
    "\n",
    "messages = [\n",
    "    {   \n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"\"\"找到DeepSeek AI公司的Fuli Luo的Google scholar 个人主页链接，并基于链接总结该人物的文章列表和引用情况，如果没有个人主页则返回no url，并搜索总结相关文章。\n",
    "            模板如下：\n",
    "            ### 基本信息\n",
    "                - 姓名：[研究者姓名]\n",
    "                - Google Scholar 个人主页链接：[Google Scholar 链接]\n",
    "\n",
    "            ### 文章列表\n",
    "                以下是 [研究者姓名] 的主要文章及其引用情况：\n",
    "                1. **[文章标题 1]** (发表年份) - 引用次数。\n",
    "                2. **[文章标题 2]** (发表年份) - 引用次数。\n",
    "                3. **[文章标题 3]** (发表年份) - 引用次数。\n",
    "                4. **[文章标题 4]** (发表年份) - 引用次数。\n",
    "                5. **[文章标题 5]** (发表年份) - 引用次数。\n",
    "                6. **[文章标题 6]** (发表年份) - 引用次数。\n",
    "                7. **[文章标题 7]** (发表年份) - 引用次数。\n",
    "                8. **[文章标题 8]** (发表年份) - 引用次数。\n",
    "                9. **[文章标题 9]** (发表年份) - 引用次数。\n",
    "                10. **[文章标题 10]** (发表年份) - 引用次数。\n",
    "            ### 引用情况\n",
    "                - **总引用次数**:\n",
    "                  - 总计:  \n",
    "                  - 2020 年至今: \n",
    "                - **h 指数**:\n",
    "                  - 总计: \n",
    "                  - 2020 年至今: \n",
    "                - **i10 指数**:\n",
    "                  - 总计: \n",
    "                  - 2020 年至今: \n",
    "\n",
    "                ### 其他相关文章\n",
    "                [研究者姓名] 还发表了多篇其他文章，涉及 [研究领域 1]、[研究领域 2] 和 [研究领域 3] 等领域。更多详细信息请访问其 Google Scholar 个人主页。\n",
    "\n",
    "            \"\"\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key=YOUR_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "# chat completion without streaming\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.1-sonar-large-128k-online\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "186586d9-8b0c-460f-b668-70cbe4ae0674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuli Luo 的 Google Scholar 个人主页链接是：\n",
      "\n",
      "[https://scholar.google.com/citations?user=1s79Z5cAAAAJ&hl=zh-CN](https://scholar.google.com/citations?user=1s79Z5cAAAAJ&hl=zh-CN)\n",
      "\n",
      "以下是基于这个链接总结的他的文章列表和引用情况：\n",
      "\n",
      "## 文章列表\n",
      "- **DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence**\n",
      "  - 作者：D Guo, Q Zhu, D Yang, Z Xie, K Dong, W Zhang, G Chen, X Bi, Y Wu, 等\n",
      "  - 引用次数：392\n",
      "  - 年份：2024[1].\n",
      "\n",
      "- **DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models**\n",
      "  - 作者：D Dai, C Deng, C Zhao, RX Xu, H Gao, D Chen, J Li, W Zeng, X Yu, Y Wu, 等\n",
      "  - 引用次数：119\n",
      "  - 年份：2024[1][2].\n",
      "\n",
      "- **A dual reinforcement learning framework for unsupervised text style transfer**\n",
      "  - 作者：F Luo, P Li, J Zhou, P Yang, B Chang, Z Sui, X Sun\n",
      "  - 引用次数：191\n",
      "  - 年份：2019[1].\n",
      "\n",
      "- **Raise a child in large language model: Towards effective and generalizable fine-tuning**\n",
      "  - 作者：R Xu, F Luo, Z Zhang, C Tan, B Chang, S Huang, F Huang\n",
      "  - 引用次数：175\n",
      "  - 年份：2021[1][2].\n",
      "\n",
      "- **Incorporating glosses into neural word sense disambiguation**\n",
      "  - 作者：F Luo, T Liu, Q Xia, B Chang, Z Sui\n",
      "  - 引用次数：116\n",
      "  - 年份：2018[1].\n",
      "\n",
      "- **Enhancing topic-to-essay generation with external commonsense knowledge**\n",
      "  - 作者：P Yang, L Li, F Luo, T Liu, X Sun\n",
      "  - 引用次数：97\n",
      "  - 年份：2019[1].\n",
      "\n",
      "- **A deep reinforced sequence-to-set model for multi-label classification**\n",
      "  - 作者：P Yang, F Luo, S Ma, J Lin, X Sun\n",
      "  - 引用次数：78\n",
      "  - 年份：2019[1].\n",
      "\n",
      "- **Leveraging gloss knowledge in neural word sense disambiguation by hierarchical co-attention**\n",
      "  - 作者：F Luo, T Liu, Z He, Q Xia, Z Sui, B Chang\n",
      "  - 引用次数：78\n",
      "  - 年份：2018[1].\n",
      "\n",
      "- **Knowledgeable Storyteller: A Commonsense-Driven Generative Model for Visual Storytelling**\n",
      "  - 作者：P Yang, F Luo, P Chen, L Li, Z Yin, X He, X Sun\n",
      "  - 引用次数：74\n",
      "  - 年份：2019[1].\n",
      "\n",
      "- **DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence**\n",
      "  - 作者：Q Zhu, D Guo, Z Shao, D Yang, P Wang, R Xu, Y Wu, Y Li, H Gao, S Ma, 等\n",
      "  - 引用次数：71\n",
      "  - 年份：2024[1].\n",
      "\n",
      "- **VECO: Variable and flexible cross-lingual pre-training for language understanding and generation**\n",
      "  - 作者：F Luo, W Wang, J Liu, Y Liu, B Bi, S Huang, F Huang, L Si\n",
      "  - 引用次数：67\n",
      "  - 年份：2020[1].\n",
      "\n",
      "- **A hierarchical reinforced sequence operation method for unsupervised text style transfer**\n",
      "  - 作者：C Wu, X Ren, F Luo, X Sun\n",
      "  - 引用次数：66\n",
      "  - 年份：2019[1].\n",
      "\n",
      "- **Hierarchical encoder with auxiliary supervision for neural table-to-text generation: Learning better representation for tables**\n",
      "  - 作者：T Liu, F Luo, Q Xia, S Ma, B Chang, Z Sui\n",
      "  - 引用次数：53\n",
      "  - 年份：2019[1].\n",
      "\n",
      "- **Towards fine-grained text sentiment transfer**\n",
      "  - 作者：F Luo, P Li, P Yang, J Zhou, Y Tan, B Chang, Z Sui, X Sun\n",
      "  - 引用次数：50\n",
      "  - 年份：2019[1].\n",
      "\n",
      "- **Cross-language document summarization via extraction and ranking of multiple summaries**\n",
      "  - 作者：X Wan, F Luo, X Sun, S Huang, J Yao\n",
      "  - 引用次数：37\n",
      "  - 年份：2019[1].\n",
      "\n",
      "- **Towards unified prompt tuning for few-shot text classification**\n",
      "  - 作者：J Wang, C Wang, F Luo, C Tan, M Qiu, F Yang, Q Shi, S Huang, M Gao\n",
      "  - 引用次数：33\n",
      "  - 年份：2022[1].\n",
      "\n",
      "- **Making pre-trained language models end-to-end few-shot learners with contrastive prompt tuning**\n",
      "  - 作者：Z Xu, C Wang, M Qiu, F Luo, R Xu, S Huang, J Huang\n",
      "  - 引用次数：27\n",
      "  - 年份：2023[1].\n",
      "\n",
      "## 其他相关文章\n",
      "更多详细的文章列表可以在提供的链接中找到，包括与DeepSeek相关的最新研究成果，如《DeepSeek LLM: Scaling Open-Source Language Models with Longtermism》和《DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search》等[2].\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6c051a1-6808-42c7-b2c9-fb207a7b7649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于提供的链接到Fuli Luo（罗福莉）的Google Scholar个人学术档案，以下是她的文章列表和引用情况的总结：\n",
      "\n",
      "## 文章列表\n",
      "\n",
      "Fuli Luo的个人学术档案列出了她参与的多篇学术文章，以下是一些主要的作品：\n",
      "\n",
      "- **DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence**\n",
      "  - 引用次数: 392\n",
      "  - 年份: 2024[4].\n",
      "\n",
      "- **A dual reinforcement learning framework for unsupervised text style transfer**\n",
      "  - 引用次数: 191\n",
      "  - 年份: 2019[4].\n",
      "\n",
      "- **Raise a child in large language model: Towards effective and generalizable fine-tuning**\n",
      "  - 引用次数: 175\n",
      "  - 年份: 2021[4].\n",
      "\n",
      "- **DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models**\n",
      "  - 引用次数: 119\n",
      "  - 年份: 2024[4].\n",
      "\n",
      "- **Incorporating glosses into neural word sense disambiguation**\n",
      "  - 引用次数: 116\n",
      "  - 年份: 2018[4].\n",
      "\n",
      "- **Enhancing topic-to-essay generation with external commonsense knowledge**\n",
      "  - 引用次数: 97\n",
      "  - 年份: 2019[4].\n",
      "\n",
      "- **A deep reinforced sequence-to-set model for multi-label classification**\n",
      "  - 引用次数: 78\n",
      "  - 年份: 2019[4].\n",
      "\n",
      "- **Leveraging gloss knowledge in neural word sense disambiguation by hierarchical co-attention**\n",
      "  - 引用次数: 78\n",
      "  - 年份: 2018[4].\n",
      "\n",
      "- **Knowledgeable Storyteller: A Commonsense-Driven Generative Model for Visual Storytelling**\n",
      "  - 引用次数: 74\n",
      "  - 年份: 2019[4].\n",
      "\n",
      "- **DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence**\n",
      "  - 引用次数: 71\n",
      "  - 年份: 2024[4].\n",
      "\n",
      "- **VECO: Variable and flexible cross-lingual pre-training for language understanding and generation**\n",
      "  - 引用次数: 67\n",
      "  - 年份: 2020[4].\n",
      "\n",
      "- **A hierarchical reinforced sequence operation method for unsupervised text style transfer**\n",
      "  - 引用次数: 66\n",
      "  - 年份: 2019[4].\n",
      "\n",
      "- **Hierarchical encoder with auxiliary supervision for neural table-to-text generation**\n",
      "  - 引用次数: 53\n",
      "  - 年份: 2019[4].\n",
      "\n",
      "- **Towards fine-grained text sentiment transfer**\n",
      "  - 引用次数: 50\n",
      "  - 年份: 2019[4].\n",
      "\n",
      "- **Cross-language document summarization via extraction and ranking of multiple summaries**\n",
      "  - 引用次数: 37\n",
      "  - 年份: 2019[4].\n",
      "\n",
      "- **Towards unified prompt tuning for few-shot text classification**\n",
      "  - 引用次数: 33\n",
      "  - 年份: 2022[4].\n",
      "\n",
      "- **Making pre-trained language models end-to-end few-shot learners with contrastive prompt tuning**\n",
      "  - 引用次数: 27\n",
      "  - 年份: 2023[4].\n",
      "\n",
      "## 引用情况\n",
      "\n",
      "- **总引用次数**:\n",
      "  - 总计: 7741 次\n",
      "  - 2019 年至今: 7343 次[4].\n",
      "\n",
      "- **h 指数**:\n",
      "  - 总计: 48\n",
      "  - 2019 年至今: 46[4].\n",
      "\n",
      "- **i10 指数**:\n",
      "  - 总计: 94\n",
      "  - 2019 年至今: 93[4].\n",
      "\n",
      "## 开放获取的出版物\n",
      "\n",
      "- **开放获取的出版物数量**:\n",
      "  - 总计: 54 篇文章（可查看的），65 篇文章（总计，包括不可查看的\")[4].\n",
      "\n",
      "这份总结涵盖了Fuli Luo的主要学术作品和她的引用情况。她的研究主要集中在自然语言处理、深度学习和机器学习领域。\n"
     ]
    }
   ],
   "source": [
    "#直接输入链接的test\n",
    "from openai import OpenAI\n",
    "\n",
    "YOUR_API_KEY = \"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\"\n",
    "\n",
    "messages = [\n",
    "    {   \n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"基于以下链接总结该人物的文章列表和引用情况：https://scholar.google.com/citations?user=1s79Z5cAAAAJ&hl=zh-CN\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key=YOUR_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "# chat completion without streaming\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-3.1-sonar-large-128k-online\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0cae0-97b5-479d-a0b7-3c3818110022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral",
   "language": "python",
   "name": "mistral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
